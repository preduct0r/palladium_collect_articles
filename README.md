# Сборщик научных статей

Этот скрипт представляет собой краулер, который собирает научные статьи и информацию о них, начиная с одной "семенной" статьи (заданной через DOI). Он рекурсивно обходит граф цитирований, скачивает PDF-файлы статей (используя открытые источники и Sci-Hub) и сохраняет всю метаинформацию в локальную базу данных SQLite.

## Как это работает

Весь процесс можно описать так:

**Старт с DOI → Получить метаданные из OpenAlex → Попытаться скачать PDF → Сохранить все в БД → Найти все статьи, которые цитируют эту → Добавить их в очередь → Повторить для каждой статьи из очереди.**

Это продолжается до тех пор, пока не будет достигнута заданная глубина обхода или общее количество обработанных статей.

### 1. Запуск и настройка

Скрипт запускается из командной строки и принимает несколько аргументов:

-   `--doi`: **Обязательный.** DOI-идентификатор или URL статьи, с которой начинается обход.
-   `--db`: Путь к файлу базы данных SQLite (по умолчанию: `./articles.db`).
-   `--out-dir`: Папка для сохранения скачанных PDF-файлов (по умолчанию: `./pdfs`).
-   `--mailto`: Ваш email для вежливого использования API OpenAlex (рекомендуется указывать).
-   `--max-depth`: Глубина обхода графа цитирований. `0` — только сама статья, `1` — статья и те, что на неё ссылаются, и т.д. (по умолчанию: `1`).
-   `--max-total`: Максимальное количество статей для обработки за один запуск.
-   `--per-parent-limit`: Максимальное количество цитирующих статей для обработки для каждой родительской статьи (по умолчанию: `50`).
-   `--sleep`: Пауза между запросами к API в секундах (по умолчанию: `1.0`).
-   `--no-scihub`: Флаг, отключающий попытку скачивания PDF через Sci-Hub, если статья не в открытом доступе.

### 2. Инициализация базы данных

Перед началом работы скрипт создаёт или подключается к базе данных SQLite. В базе создаются две основные таблицы:

1.  `articles`: Хранит всю информацию о каждой статье: DOI, ID в OpenAlex, заголовок, год, статус открытого доступа (Open Access), количество цитирований, путь к скачанному PDF и т.д. `DOI` является первичным ключом.
2.  `relations`: Хранит связи между статьями (граф цитирований). Содержит поля `from_doi` (кого цитируют) и `to_doi` (кто цитирует).

### 3. Обход графа цитирований

-   Скрипт использует алгоритм **поиска в ширину (BFS)** для обхода графа.
-   Создается очередь, в которую помещаются статьи для обработки.
-   Обход начинается с "семенной" статьи и продолжается, пока очередь не опустеет или не будет достигнут лимит `--max-total`.
-   Используется множество `visited` для отслеживания уже обработанных DOI, чтобы избежать повторной работы и зацикливания.

### 4. Обработка одной статьи

Для каждой статьи выполняются следующие шаги:

1.  **Получение метаданных**: Отправляется запрос к API OpenAlex для получения полной информации о статье по её DOI.
2.  **Загрузка PDF**: Скрипт пытается скачать PDF:
    -   Сначала он проверяет прямую ссылку на PDF в данных OpenAlex (если статья в открытом доступе).
    -   Если это не удалось и опция `--no-scihub` не установлена, скрипт использует библиотеку `sci_hub` для поиска и скачивания PDF через Sci-Hub.
3.  **Сохранение в БД**: Информация о статье, включая путь к скачанному PDF и источник (`openalex` или `scihub`), сохраняется в таблицу `articles`.
4.  **Поиск цитирующих статей**: Скрипт делает запросы к API OpenAlex, чтобы найти все статьи, которые ссылаются на текущую.
5.  **Добавление дочерних статей в очередь**: Каждая найденная цитирующая статья ("ребенок") добавляется в базу данных, создается связь в таблице `relations`, и статья добавляется в очередь для дальнейшей обработки, если не превышена глубина обхода.

## Требования

- Python 3.7+
- `requests`
- `sci_hub` (опционально, для скачивания закрытых статей)

Установить зависимости:
```bash
pip install requests
pip install sci-hub-next
```
*Примечание: оригинальный пакет `sci-hub` может быть недоступен, используйте `sci-hub-next` или другой форк.*

## Пример запуска

```bash
python main.py \
    --doi "10.1038/s41586-020-2649-2" \
    --mailto "your.email@example.com" \
    --max-depth 2 \
    --per-parent-limit 10
``` 